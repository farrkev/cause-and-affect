{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Owner\\Desktop\\MSc\\Thesis\\cause-and-affect\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "\n",
    "from itertools import product\n",
    "from pgmpy.models import LinearGaussianBayesianNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _concordance_correlation_coefficient(x, y):\n",
    "    # https://nirpyresearch.com/concordance-correlation-coefficient/\n",
    "    sxy = np.sum((x - x.mean())*(y - y.mean()))/x.shape[0]\n",
    "    rhoc = 2*sxy / (np.var(x) + np.var(y) + (x.mean() - y.mean())**2)\n",
    "    return rhoc\n",
    "\n",
    "def _compute_metrics(y_true, y_pred):\n",
    "    pearson_r_arousal = np.corrcoef(y_true[:, 0], y_pred[:, 0])[0, 1]\n",
    "    pearson_r_valence = np.corrcoef(y_true[:, 1], y_pred[:, 1])[0, 1]\n",
    "    ccc_arousal = _concordance_correlation_coefficient(y_true[:, 0], y_pred[:, 0])\n",
    "    ccc_valence = _concordance_correlation_coefficient(y_true[:, 1], y_pred[:, 1])\n",
    "    return pearson_r_arousal, pearson_r_valence, ccc_arousal, ccc_valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_network_from_dag(dag_file_path:str, method:str, train_set:pd.DataFrame):\n",
    "    # open the DAG in binary read mode\n",
    "    with open(dag_file_path, \"rb\") as file:\n",
    "        dag_data = pkl.load(file)\n",
    "\n",
    "    graph_matrix = (\n",
    "        dag_data[\"G\"].graph if method == \"ges\" \n",
    "        else dag_data[0].graph if method in [\"fci\", \"pruned_fci\"]\n",
    "        else dag_data.G.graph if method in [\"pc\", \"pruned_pc\"]\n",
    "        else dag_data if method == \"avg\"\n",
    "        else None\n",
    "    )\n",
    "\n",
    "    # extract edges from the learned DAG\n",
    "    num_nodes = graph_matrix.shape[0]\n",
    "    edges = []\n",
    "\n",
    "    # iterate through all node pairs to determine edge types\n",
    "    for i, j in product(range(num_nodes), range(num_nodes)):\n",
    "        if graph_matrix[i, j] == -1 and graph_matrix[j, i] == 1:  # fully directed edge i --> j\n",
    "            edges.append((str(i), str(j)))\n",
    "        # elif graph_matrix[i, j] == graph_matrix[j, i] == 1:  # bidirected edge i <-> j\n",
    "        #     edges.append((str(i), str(j)))\n",
    "        #     edges.append((str(j), str(i)))\n",
    "        # elif graph_matrix[i, j] == 2 and graph_matrix[j, i] == 1:  # i o-> j partially directed\n",
    "        #     edges.append((str(i), str(j)))\n",
    "            # partially_directed_edges_count += 1\n",
    "\n",
    "    assert nx.is_directed_acyclic_graph(nx.DiGraph(edges)), \"Graph is not a DAG.\"\n",
    "\n",
    "    # train a LGBN on the corresponding participant's data\n",
    "    lgbn_model = LinearGaussianBayesianNetwork(edges)\n",
    "    lgbn_model.fit(train_set)\n",
    "\n",
    "    return lgbn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure to pass into `models` all but one model\n",
    "def make_predictions(models: dict, test_set: pd.DataFrame) -> tuple[pd.DataFrame, dict]:\n",
    "    clean_test_set = test_set.drop(\"Participant\", axis=1).copy()\n",
    "    rename_dict = {\n",
    "        \"median_arousal\": \"0\",\n",
    "        \"median_valence\": \"1\",\n",
    "    }\n",
    "    rename_dict.update({f\"PC{i}\": str(i + 1) for i in range(1, test_set.shape[1] - 2)})\n",
    "    clean_test_set = clean_test_set.rename(columns=rename_dict).reset_index(drop=True)\n",
    "\n",
    "    # splitting into labels and features\n",
    "    y_test = clean_test_set[[\"0\", \"1\"]].values\n",
    "    X_test = clean_test_set.drop([\"0\", \"1\"], axis=1)\n",
    "\n",
    "    all_results = []\n",
    "    y_pred_arousal_ensemble = []\n",
    "    y_pred_valence_ensemble = []\n",
    "    \n",
    "    for model_id, model in models.items():\n",
    "        try:\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            # NOTE:\n",
    "            # it may be the case that the model (graph) does not contain\n",
    "            # all the nodes contained in the training/test data, making it\n",
    "            # impossible to make predictions. Here I am catering for such\n",
    "            # cases by filling up missing predictions with `np.nan`.\n",
    "            if len(y_pred[0]) == 1:\n",
    "                y_pred[0].append('1' if '0' in y_pred[0] else '0')\n",
    "                y_pred[1] = np.hstack((y_pred[1], np.full((len(y_pred[1]), 1), np.nan)))\n",
    "        except Exception as e:\n",
    "            # in case of failure, initialize fallback values\n",
    "            y_pred = [None, None]\n",
    "            y_pred[0] = [\"1\", \"0\"]\n",
    "            y_pred[1] = np.full((len(X_test), 2), np.nan)\n",
    "\n",
    "        predicted_means = y_pred[1]\n",
    "\n",
    "        arousal_idx = y_pred[0].index(\"0\")\n",
    "        valence_idx = y_pred[0].index(\"1\")\n",
    "\n",
    "        y_pred_arousal = predicted_means[:, arousal_idx]\n",
    "        y_pred_valence = predicted_means[:, valence_idx]\n",
    "\n",
    "        # storing all predictions\n",
    "        temp_df = test_set[[\"Participant\", \"median_arousal\", \"median_valence\"]].copy()\n",
    "        temp_df[f\"prd_lgbn_{model_id}_arousal\"] = y_pred_arousal\n",
    "        temp_df[f\"prd_lgbn_{model_id}_valence\"] = y_pred_valence\n",
    "        all_results.append(temp_df)\n",
    "\n",
    "        # append predictions for ensemble calculation\n",
    "        y_pred_arousal_ensemble.append(y_pred_arousal)\n",
    "        y_pred_valence_ensemble.append(y_pred_valence)\n",
    "    \n",
    "    # NOTE: use nanmean? this ignores nan from computation\n",
    "    y_pred_arousal_ensemble = np.nanmean(y_pred_arousal_ensemble, axis=0)\n",
    "    y_pred_valence_ensemble = np.nanmean(y_pred_valence_ensemble, axis=0)\n",
    "\n",
    "    all_predictions_df = pd.concat(all_results, axis = 1)\n",
    "    all_predictions_df = all_predictions_df.loc[:, ~all_predictions_df.columns.duplicated()]\n",
    "\n",
    "    # storing ensemble predictions\n",
    "    temp_df = test_set[[\"Participant\", \"median_arousal\", \"median_valence\"]].copy()\n",
    "    temp_df[f\"prd_lgbn_ensemble_arousal\"] = y_pred_arousal_ensemble\n",
    "    temp_df[f\"prd_lgbn_ensemble_valence\"] = y_pred_valence_ensemble\n",
    "\n",
    "    participant_predictions_df = pd.concat([all_predictions_df, temp_df], axis=1)\n",
    "    participant_predictions_df = participant_predictions_df.loc[:, ~participant_predictions_df.columns.duplicated()]\n",
    "\n",
    "    # compute evaluation metrics\n",
    "    (\n",
    "        lgbn_pearson_r_arousal,\n",
    "        lgbn_pearson_r_valence,\n",
    "        lgbn_ccc_arousal,\n",
    "        lgbn_ccc_valence\n",
    "    ) = _compute_metrics(y_test, np.column_stack((y_pred_arousal_ensemble, y_pred_valence_ensemble)))\n",
    "\n",
    "    evaluations = {\n",
    "        \"pearson_r_arousal\": lgbn_pearson_r_arousal,\n",
    "        \"pearson_r_valence\": lgbn_pearson_r_valence,\n",
    "        \"ccc_arousal\": lgbn_ccc_arousal,\n",
    "        \"ccc_valence\": lgbn_ccc_valence\n",
    "    }\n",
    "\n",
    "    return participant_predictions_df, evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing visual, ges...\n",
      "Processing visual, pruned_fci...\n",
      "Processing visual, pruned_pc...\n",
      "Processing audio, ges...\n",
      "Processing audio, pruned_fci...\n",
      "Processing audio, pruned_pc...\n",
      "Processing physio, ges...\n",
      "Processing physio, pruned_fci...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_1200\\2998334823.py:56: RuntimeWarning: Mean of empty slice\n",
      "  y_pred_arousal_ensemble = np.nanmean(y_pred_arousal_ensemble, axis=0)\n",
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_1200\\2998334823.py:57: RuntimeWarning: Mean of empty slice\n",
      "  y_pred_valence_ensemble = np.nanmean(y_pred_valence_ensemble, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing physio, pruned_pc...\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"visual\": {\n",
    "        \"ges\": [16,19,23,25,26,28,30,34,37,39,42,45,46,56,64,65], # missing 21, 41\n",
    "        \"pruned_fci\": [16,19,21,23,25,26,28,30,34,37,39,41,42,45,46,56,64,65],\n",
    "        \"pruned_pc\": [16,19,21,23,25,26,28,30,34,37,39,41,42,45,46,56,64,65],\n",
    "    },\n",
    "    \"audio\": {\n",
    "        \"ges\": [16,19,21,23,25,26,28,30,34,37,39,41,42,45,46,56,64,65],\n",
    "        \"pruned_fci\": [16,19,21,23,25,26,28,30,34,37,39,41,42,45,46,56,64,65],\n",
    "        \"pruned_pc\": [16,19,21,23,25,26,28,30,34,37,39,41,42,45,46,56,64,65],\n",
    "    },\n",
    "    \"physio\": {\n",
    "        \"ges\": [16,19,23,25,26,28,30,34,37,39,41,42,45,46,56,64,65], # missing 21\n",
    "        \"pruned_fci\": [16,19,21,23,25,26,28,30,34,37,39,41,42,45,46,56,64,65],\n",
    "        \"pruned_pc\": [16,19,21,23,25,26,28,30,34,37,39,41,42,45,46,56,64,65],\n",
    "    },\n",
    "}\n",
    "\n",
    "all_evals = []\n",
    "all_modalities_results = []\n",
    "for modality, v in data.items():\n",
    "    all_methods_results = []\n",
    "    for method, dag_participant_ids in v.items():\n",
    "        print(f\"Processing {modality}, {method}...\")\n",
    "        modality_df = pd.read_csv(f\"../data/subset_{modality}_pca.csv\")\n",
    "        participants = modality_df[\"Participant\"].unique()\n",
    "        participants.sort()\n",
    "\n",
    "        rename_dict = {\n",
    "                \"median_arousal\": \"0\",\n",
    "                \"median_valence\": \"1\",\n",
    "            }\n",
    "        rename_dict.update({f\"PC{i}\": str(i + 1) for i in range(1, modality_df.shape[1] - 2)})\n",
    "\n",
    "        # getting all LGBN models for each modality-method combination\n",
    "        model_bank = {}\n",
    "        for dag_id in dag_participant_ids:\n",
    "            # filtering data for relevant participant\n",
    "            train_set = modality_df[modality_df[\"Participant\"] == dag_id]\n",
    "            train_set = train_set.drop(\"Participant\", axis=1)\n",
    "            train_set = train_set.rename(columns=rename_dict).reset_index(drop=True)\n",
    "\n",
    "            # getting path to relevant DAG\n",
    "            dag_file_path = f\"../results_dag/{modality}/{method}_dag_participant_{dag_id}.pkl\"\n",
    "\n",
    "            model_bank[dag_id] = bayesian_network_from_dag(\n",
    "                dag_file_path,\n",
    "                method,\n",
    "                train_set\n",
    "            )\n",
    "\n",
    "        # generate predictions per participant\n",
    "        all_participants_results = []\n",
    "        for participant in participants:\n",
    "            # generating model from average graph\n",
    "            train_set_avg_graph = modality_df[modality_df[\"Participant\"] != participant]\n",
    "            train_set_avg_graph = train_set_avg_graph.drop(\"Participant\", axis=1)\n",
    "            train_set_avg_graph = train_set_avg_graph.rename(columns=rename_dict).reset_index(drop=True)\n",
    "\n",
    "            avg_dag_file_path = f\"../results_dag/{modality}/avg_{method}_dag.pkl\"\n",
    "            average_graph_model = bayesian_network_from_dag(\n",
    "                avg_dag_file_path,\n",
    "                \"avg\",\n",
    "                train_set_avg_graph\n",
    "            )\n",
    "\n",
    "            # considering all models except for current participant's\n",
    "            models_to_consider = {k: v for k, v in model_bank.items() if k != participant}\n",
    "            test_set = modality_df[modality_df[\"Participant\"] == participant]\n",
    "\n",
    "            participant_predictions_df, evaluations = make_predictions(models_to_consider, test_set)\n",
    "\n",
    "            # generating predictions using average graph\n",
    "            avg_dag_participant_predictions_df, avg_dag_evaluations = make_predictions(\n",
    "                {\"avg\": average_graph_model},\n",
    "                test_set\n",
    "            )\n",
    "            \n",
    "            # ensemble results are redundant here\n",
    "            avg_dag_participant_predictions_df = avg_dag_participant_predictions_df.drop(\n",
    "                [\"Participant\", \"median_arousal\", \"median_valence\", \"prd_lgbn_ensemble_arousal\", \"prd_lgbn_ensemble_valence\"], \n",
    "                axis=1\n",
    "            )\n",
    "            \n",
    "            evaluations = {\n",
    "                f\"{modality}_{method}_\" + key: value \n",
    "                for key, value \n",
    "                in evaluations.items()\n",
    "            }\n",
    "            evaluations[\"participant\"] = participant\n",
    "            all_evals.append(evaluations)\n",
    "\n",
    "            avg_dag_evaluations = {\n",
    "                f\"avg_{modality}_{method}_\" + key: value \n",
    "                for key, value \n",
    "                in avg_dag_evaluations.items()\n",
    "            }\n",
    "            avg_dag_evaluations[\"participant\"] = participant\n",
    "            all_evals.append(avg_dag_evaluations)\n",
    "            \n",
    "            participant_predictions_df.columns = participant_predictions_df.columns.str.replace(\n",
    "                \"prd\",\n",
    "                f\"{modality}_{method}\"\n",
    "            )\n",
    "            avg_dag_participant_predictions_df.columns = avg_dag_participant_predictions_df.columns.str.replace(\n",
    "                \"prd\",\n",
    "                f\"avg_{modality}_{method}\"\n",
    "            )\n",
    "\n",
    "            all_participants_results.append(pd.concat([participant_predictions_df, avg_dag_participant_predictions_df], axis=1))\n",
    "        all_methods_results.append(pd.concat(all_participants_results, axis=0))\n",
    "    all_methods_results_df = pd.concat(all_methods_results, axis=1)\n",
    "    all_methods_results_df = all_methods_results_df.loc[:, ~all_methods_results_df.columns.duplicated()]\n",
    "    all_modalities_results.append(all_methods_results_df)\n",
    "\n",
    "all_predicitons_df = pd.concat(all_modalities_results, axis=1)\n",
    "all_predicitons_df = all_predicitons_df.loc[:, ~all_predicitons_df.columns.duplicated()]\n",
    "all_predicitons_df.to_csv(\"../results/data_with_predictions.csv\", index=False)\n",
    "\n",
    "all_evals_df = pd.DataFrame(all_evals)\n",
    "all_evals_df = all_evals_df.groupby(\"participant\").first()\n",
    "all_evals_df.to_csv(\"../results/lgbn_ensemble_evaluations.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
